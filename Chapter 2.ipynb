{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 2\n",
    "## Numeric Attributes\n",
    "\n",
    "## 2.1 Univariate Analysis \n",
    "* Data matrix D can be a n x 1 matrix (simply a column vector).\n",
    "$D = \\begin{bmatrix}X \\\\ x_1\\\\x_2\\\\...\\\\x_n\\end{bmatrix}$ <br/>\n",
    "* X is the numeric attribute of interest and each point can be an identity random variables.\n",
    "\n",
    "### Empirical Cumulative Distribution Function (CDF)\n",
    "$F(x) = \\frac{1}{n}\\sum_{i=1}^{n}I(x_i <=x)$ <br/>\n",
    "where <br/>\n",
    "$I(x_i<=x) = \\begin{cases}1, & \\text{if } x_i <= x \\\\ 0, & \\text{if } x_i > x \\end{cases}$ <br/>\n",
    "I is a binary indicator variable that indicates whether the given condition is satisfied. This function essentially checks to see how many values in the data set are <= the given x and divide it by the sample size (essentially the frequency of points that are <= x).\n",
    "\n",
    "### Inverse Cumulative Distribution Function\n",
    "\n",
    "$F^{-1}(q) = min{x|F(x) >= q}$ for $q\\in[0,1]$ <br/> \n",
    "Gives the least value of X for which q % of the values are higher than x and 1-q% is lower. <br/>\n",
    "$F^{-1}(0.75)$ will return the value that corresponds to the 75th percentile (3rd quartile)\n",
    "\n",
    "### Empirical Porbaiblity Mass Function (PMF)\n",
    "\n",
    "$F(x) = \\frac{1}{n}\\sum_{i=1}^{n}I(x_i = x)$ <br/>\n",
    "where <br/>\n",
    "$I(x_i<=x) = \\begin{cases}1, & \\text{if } x_i = x \\\\ 0, & \\text{if } x_i != x \\end{cases}$ <br/>\n",
    "If the values are equal then it will be 1, counts the number of times a certain number appears in the dataset.\n",
    "\n",
    "### 2.1.1 Measures of Central Tendency\n",
    "\n",
    "#### Mean\n",
    "\n",
    "* Also known as expected value for discrete distributions: \n",
    "$\\mu = E[X] = \\sum_{x}xf(x)$ \n",
    "* For continuous distributions\n",
    "$\\mu = E[X] = \\int_{-\\infty}^{\\infty}xf(x)dx$\n",
    "\n",
    "#### Sample Mean\n",
    "* Same idea as mean but for within the sample\n",
    "\n",
    "#### Sample mean is Unbiased\n",
    "* An estimator,x, is unbiased for a parameter,y, if E(x) = y. Sample mean will be denoted as $\\mu^{x}$\n",
    "$E[\\mu^{x}] = E[\\frac{1}{n}\\sum_{i=1}^{n}x_i] = \\frac{1}{n}\\sum_{i=1}^{n}E[x_i] = \\frac{1}{n}\\sum_{i=1}^{n}\\mu = \\mu$\n",
    "\n",
    "#### Robustness \n",
    "\n",
    "* A statistic is robust if it's not affected by extreme values\n",
    "    * Sample mean is not robust.\n",
    "    * Trimmed mean, discards small fraction of extreme values on one or both ends, is robust.\n",
    "    * Median is robust.\n",
    "    \n",
    "#### Median\n",
    "* Defined as $P(X <= m) >= \\frac{1}{2} \\text{and} P(X >= m) >= \\frac{1}{2}$ <br/>\n",
    "* Is the middle most value, half of the vlaues of X are less than m and half of the vlaues of X are more than m.\n",
    "\n",
    "#### Mode\n",
    "* value at which it appears the most, mathematically defined to be: <br/>\n",
    "$ mode(X) = arg max f(x)$\n",
    "* Example 2.1 shows sample mean, median, and mode.\n",
    "### 2.1.2 Measures of Dispersion\n",
    "\n",
    "Robustness:\n",
    "* range is not robust (max and min values are directly part of the calculation) \n",
    "\n",
    "\n",
    "#### Range\n",
    "* Difference between max and min values of X <br/>\n",
    "$r = max(X) - min(X)$\n",
    "\n",
    "#### Inter-Quartile Range\n",
    "* third quartile - first quartile. \n",
    "$ F^{-1}(0.75) - F^{-1}(0.25)$\n",
    "\n",
    "#### Variance and Standard Deviation\n",
    "* Variance of a random variable X shows how the values deviate from the mean. Formally it is defined as <br/>\n",
    "$ \\sigma^2 = var(X) = E[(X-\\mu)^2] = \\begin{cases} \\sum_x(x-\\mu)^2 f(x), & \\text{if X is discrete} \\\\ \\int_{-\\infty}^{\\infty}(x-\\mu)^2f(x)dx, & \\text{if X is continuous} \\end{cases}$\n",
    "* Standard deviation $\\sigma$ is just the square root of variance $\\sqrt{var(X)}$\n",
    "* variance can also e written as <br/>\n",
    "$ var(X) = E[X^2] - (E[X])^2$ <br/> \n",
    "\n",
    "#### Sample Variance\n",
    "* It is just the variance for a sample, so the mean used is the sample mean. Stastics are denoted as the parameter with a carat, for example the parameter mean would be denoted as $\\hat{\\mu}$ for the sample version. <br/>\n",
    "$ \\hat{\\sigma}^2 = \\frac{1}{n}\\sum_{i=1}^{n}(X_i - \\hat{\\mu})^2$\n",
    "* Z-score, also known as the standard score, is the number of standard deviations away the value is from the mean <br/>\n",
    "$ z_i = \\frac{x_i - \\hat{\\mu}}{\\hat{\\mu}}$\n",
    "\n",
    "#### Geometric Interpretation of Sample Variance \n",
    "* We can write out the z-score in the form of a matrix given data with <br/> \n",
    "$ Z = X - 1 * \\hat{\\mu} = \\begin{bmatrix} x_1 - \\hat{\\mu} \\\\ x_2 - \\hat{\\mu} \\\\ ... \\\\ x_n - \\hat{\\mu} \\end{bmatrix}$ <br/>\n",
    "* We can write the sample variance in terms of Z with <br/>\n",
    "$ \\hat{\\mu}^2 = \\frac{1}{n} ||Z|| ^2 = \\frac{1}{n}Z^{T}Z = \\frac{1}{n}\\sum_{i=1}^{n}(x_i - \\hat{\\mu})^2$\n",
    "\n",
    "#### Variance of the Sample Mean\n",
    "* We can derive an expression for the variance of the sample mean by assuming that the random variables are all independent. \n",
    "$var(\\sum_{i=1}^{n}x_i) = \\sum_{i=1}^{n}var(x_i)$ <br/>\n",
    "$var(x_i) = \\sigma^2 \\text{for all i}$ <br/>\n",
    "$var(\\sum_{i=1}^{n}x_i) = \\sum_{i=1}^{n}var(x_i) = \\sum_{i=1}^{n}\\sigma^2 = n\\sigma^2$ <br/>\n",
    "$E[\\sum_{i=1}^{n}x_i] = n\\mu$ <br/>\n",
    "* To get the mean, we would need to do $\\frac{1}{n}\\sum_{i=1}^{n}x_i$. We know that $E[X] = \\mu$ so theoretically the expected value of all values in X should be the mean multiplied by the number of values there are. We can use the top equations to get <br/>\n",
    "$var(\\hat{\\mu}) = \\frac{\\sigma^2}{n}$ <br/>\n",
    "* The sample mean $\\hat{\\mu}$ varies or deviates from the mean in proportion to the population variance $\\sigma^2$. However, the deviation can be made smaller with the sample size $n$.\n",
    "\n",
    "#### Sample Variance s Biased, but is Asymptotically Unbiased.\n",
    "$E[\\hat{\\sigma}^2] = \\frac{1}{n}n\\sigma^2 - \\frac{\\sigma^2}{n} = \\frac{n-1}{n}\\sigma^2$\n",
    "* However as n approaches infinity, $\\hat{\\sigma}^2$ becomes an unbiased estimator of population variance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Bivariate Analysis\n",
    "* We can put two attributes into a data matrix with\n",
    "$D = \\begin{bmatrix}X_1 | X_2 \\\\ x_{11}, x_{12} \\\\ x_{21}, x_{22} \\\\ ... \\\\ x_{n1} x_{n2} \\end{bmatrix}$\n",
    "\n",
    "#### Empirical Joint Probability Mass Function\n",
    "* sums the number of occurances of a certain observation. \n",
    "\n",
    "### 2.2.1 Measures of Location and Dispersion\n",
    "#### Mean\n",
    "$\\mu = E[X] = E[\\begin{bmatrix}X1 \\\\ X2\\end{bmatrix}] = \\begin{bmatrix}\\mu_1 \\\\ \\mu_2 \\end{bmatrix}$\n",
    "\n",
    "#### Variance\n",
    "* We can use the total variance which is $\\sigma_1^2$ for X_1 and $\\sigma_2^2$ for X_2\n",
    "* total variance is given as <br/>\n",
    "$var(D) = \\sigma_1^2 + \\sigma_2^2$\n",
    "* same can be applied to sample variance \n",
    "\n",
    "### 2.2.2 Measures of Association\n",
    "#### Covariance\n",
    "* *covariance* between two attributes provides a measure of association between them. Covariance between X1 and X2 is defined as $\\sigma_{12} = E[X_1X_2] -E[X_1]E[X_2]$\n",
    "* If $X_1$ and $X_2$ are indpendent, then we can conclude that $E[X_1X_2] = E[X_1]*E[X_2]$ which implies that $\\sigma_{12} = 0$\n",
    "    * However, we can't say that if the covariance between two variables is 0, that the variables are indpenedent of one another BECAUSE there might be a higher order relationship betweeen them two that exceeds beyond linear. \n",
    "* $\\hat{\\sigma_{11}} = \\hat{\\sigma_{1}}^2$\n",
    "\n",
    "#### Correlation\n",
    "* Standardized covariance, obtained by normalizing the coveriance with the standard deviation of each variable. <br/>\n",
    "$\\rho_{12} = \\frac{\\sigma_{12}}{\\sigma_{1} \\sigma_{2}}$\n",
    "\n",
    "#### Geometric Interpretation of Sample Covariance and Correlation\n",
    "$Z_1 = X_1 - 1 * \\hat{\\mu_1} = \\begin{bmatrix} x_{11} - \\hat{\\mu_1} \\\\ x_{21} - \\hat{\\mu_1} \\\\ ... \\\\ x_{n1}-\\hat{\\mu_1}\\end{bmatrix}$\n",
    "\n",
    "$Z_2 = X_2 - 1 * \\hat{\\mu_2} = \\begin{bmatrix} x_{12} - \\hat{\\mu_2} \\\\ x_{22} - \\hat{\\mu_2} \\\\ ... \\\\ x_{n2}-\\hat{\\mu_1}\\end{bmatrix}$ <br/>\n",
    "\n",
    "The sample covariance can be written as $\\hat{\\rho_{12}} = \\frac{Z_1^TZ_2}{n}$\n",
    "\n",
    "#### Covariance Matrix\n",
    "* Covariance matrix can be summarized as <br/>\n",
    "$\\sum = \\begin{bmatrix} \\sigma_1^2, \\sigma_{12} \\\\ \\sigma_{21}, \\sigma_2^2 \\end{bmatrix}$ which is a symmetric matrix. The total variance is $var(D) = tr(\\sigma) = \\sigma_1^2 + \\sigma_2^2$ where tr() is the trace of a matrix, which is the sum of the diagonal elements.\n",
    "* We can say that tr($\\sum$) >= 0, since variance can never be negative. The sample covariance matrix is given as: <br/>\n",
    "$\\hat{\\sum} = \\begin{bmatrix} \\hat{\\sigma_1^2}, \\hat{\\sigma_{12}} \\\\ \\hat{\\sigma_{21}}, \\hat{\\sigma_2^2} \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Multivariate Analysis\n",
    "* The data matrix D hasa d attributes $X_d$ (columns) and n rows $x_n$ (observations). \n",
    "\n",
    "#### Mean\n",
    "* The mean is obtained by taking the mean of each attribute\n",
    "$\\mu = E[X] = \\begin{bmatrix} E[X_1] \\\\ E[X_2] \\\\ ... \\\\ E[X_d] \\end{bmatrix} = \\begin{bmatrix} \\mu_1 \\\\ \\mu_2 \\\\ ... \\\\ \\mu_d \\end{bmatrix}$\n",
    "\n",
    "#### Covariance Matrix\n",
    "$\\sum = E[(X-\\mu)(X-\\mu)^T] = \\begin{bmatrix}\\sigma_1^2, \\sigma_{12}, ..., \\sigma_{1d} \\\\ \\sigma_{21}, \\sigma_2^2, ..., \\sigma_{2d} \\\\ ..., ..., ..., ... \\\\ \\sigma_{d1}, \\sigma_{d2}, ..., \\sigma_d^2 \\end{bmatrix}$\n",
    "* The off diagonal elements $\\sigma_{ij} = \\sigma_{ji}$ represents the covariance between attribute pairs $X_i$ and $X_j$. \n",
    "\n",
    "#### Total and Generalized Variance \n",
    "$ var(D) = tr(D) = \\sigma_1^3 + \\sigma_2^2 + ... + \\sigma_d^2$ total variance must be non-negative. \n",
    "\n",
    "#### Sample Covariance Matrix\n",
    "* Let  represent the centered data matrix given as the matrix of centered attributes vectors $Z_i = X_i - 1*\\hat{\\mu_i}$ <br/>\n",
    "$ Z = D - 1 * \\hat{\\mu^T} = (Z_1 Z_2 ... Z_d) $ <br/> \n",
    "$ \\hat{\\sum} = \\frac{1}{n}(Z^T * Z) = \\frac{1}{n} \\begin{bmatrix} Z_1^T * Z_1, Z_1^T * Z_2, ..., Z_1^T * Z_d \\\\ Z_2^T * Z_1, Z_2^T * Z_2, ..., Z_2^T * Z_d \\\\ ..., ..., ..., ... \\\\ Z_d^T * Z_1, Z_d^T * Z_2, ..., Z_d^T * Z_d \\end{bmatrix}$\n",
    "* the sample covariance matrix is the dot product of the normalized values divided by the sample size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>2.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>5.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A1   A2\n",
       "0   1  0.8\n",
       "1   5  2.4\n",
       "2   9  5.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.DataFrame({'A1':[1,5,9], 'A2':[0.8, 2.4, 5.5]})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A1    5.0\n",
       "A2    2.9\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mu_sample = df.mean()\n",
    "mu_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z = df - np.ones((3,1)) * mu_sample.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10.66666667,  6.26666667],\n",
       "       [ 6.26666667,  3.80666667]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov = 1/3 * np.dot(Z.T.values, Z.values)\n",
    "cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Data Normalization \n",
    "#### Range Normalization \n",
    "Let X be an attribute, range normalization is scaled with the following values: <br/>\n",
    "$ x_i = \\frac{x_i - min_i{x_i}}{max_i{x_i} - min_i{x_i}}$ <br/> \n",
    "Each new attribute whould take on values between [0, 1]\n",
    "\n",
    "#### Standard Score Normalization \n",
    "* It is just z-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Normal Distribution\n",
    "Read the chapter a lot of it is just review. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
